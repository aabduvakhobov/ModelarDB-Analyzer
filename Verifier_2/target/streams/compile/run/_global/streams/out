[error] java.lang.IllegalStateException: Cannot call methods on a stopped SparkContext.
[error] This stopped SparkContext was created at:
[error] 
[error] org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:943)
[error] dk.aau.modelardb.storage.FileStorage.open(FileStorage.scala:116)
[error] dk.aau.modelardb.Evaluate$.verifyError(Evaluate.scala:114)
[error] dk.aau.modelardb.Evaluate$.verifier(Evaluate.scala:38)
[error] dk.aau.modelardb.Main$.main(Main.scala:62)
[error] dk.aau.modelardb.Main.main(Main.scala)
[error] java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[error] java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
[error] java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
[error] java.base/java.lang.reflect.Method.invoke(Method.java:566)
[error] sbt.Run.invokeMain(Run.scala:143)
[error] sbt.Run.execute$1(Run.scala:93)
[error] sbt.Run.$anonfun$runWithLoader$5(Run.scala:120)
[error] sbt.Run$.executeSuccess(Run.scala:186)
[error] sbt.Run.runWithLoader(Run.scala:120)
[error] sbt.Run.run(Run.scala:127)
[error] sbt.Defaults$.$anonfun$runTask$3(Defaults.scala:2028)
[error] sbt.Defaults$.$anonfun$runTask$3$adapted(Defaults.scala:2026)
[error] scala.Function1.$anonfun$compose$1(Function1.scala:49)
[error] sbt.internal.util.$tilde$greater.$anonfun$$u2219$1(TypeFunctions.scala:62)
[error] 
[error] The currently active SparkContext was created at:
[error] 
[error] org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:943)
[error] dk.aau.modelardb.storage.FileStorage.open(FileStorage.scala:116)
[error] dk.aau.modelardb.Evaluate$.verifyError(Evaluate.scala:114)
[error] dk.aau.modelardb.Evaluate$.verifier(Evaluate.scala:38)
[error] dk.aau.modelardb.Main$.main(Main.scala:62)
[error] dk.aau.modelardb.Main.main(Main.scala)
[error] java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[error] java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
[error] java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
[error] java.base/java.lang.reflect.Method.invoke(Method.java:566)
[error] sbt.Run.invokeMain(Run.scala:143)
[error] sbt.Run.execute$1(Run.scala:93)
[error] sbt.Run.$anonfun$runWithLoader$5(Run.scala:120)
[error] sbt.Run$.executeSuccess(Run.scala:186)
[error] sbt.Run.runWithLoader(Run.scala:120)
[error] sbt.Run.run(Run.scala:127)
[error] sbt.Defaults$.$anonfun$runTask$3(Defaults.scala:2028)
[error] sbt.Defaults$.$anonfun$runTask$3$adapted(Defaults.scala:2026)
[error] scala.Function1.$anonfun$compose$1(Function1.scala:49)
[error] sbt.internal.util.$tilde$greater.$anonfun$$u2219$1(TypeFunctions.scala:62)
[error]          
[error] 	at org.apache.spark.SparkContext.assertNotStopped(SparkContext.scala:118)
[error] 	at org.apache.spark.SparkContext.defaultParallelism(SparkContext.scala:2510)
[error] 	at org.apache.spark.sql.SparkSession.$anonfun$leafNodeDefaultParallelism$1(SparkSession.scala:781)
[error] 	at scala.runtime.java8.JFunction0$mcI$sp.apply(JFunction0$mcI$sp.java:23)
[error] 	at scala.Option.getOrElse(Option.scala:189)
[error] 	at org.apache.spark.sql.SparkSession.leafNodeDefaultParallelism(SparkSession.scala:781)
[error] 	at org.apache.spark.sql.execution.datasources.FilePartition$.$anonfun$maxSplitBytes$1(FilePartition.scala:92)
[error] 	at scala.runtime.java8.JFunction0$mcI$sp.apply(JFunction0$mcI$sp.java:23)
[error] 	at scala.Option.getOrElse(Option.scala:189)
[error] 	at org.apache.spark.sql.execution.datasources.FilePartition$.maxSplitBytes(FilePartition.scala:92)
[error] 	at org.apache.spark.sql.execution.FileSourceScanExec.createReadRDD(DataSourceScanExec.scala:608)
[error] 	at org.apache.spark.sql.execution.FileSourceScanExec.inputRDD$lzycompute(DataSourceScanExec.scala:432)
[error] 	at org.apache.spark.sql.execution.FileSourceScanExec.inputRDD(DataSourceScanExec.scala:417)
[error] 	at org.apache.spark.sql.execution.FileSourceScanExec.doExecuteColumnar(DataSourceScanExec.scala:516)
[error] 	at org.apache.spark.sql.execution.SparkPlan.$anonfun$executeColumnar$1(SparkPlan.scala:211)
[error] 	at org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:222)
[error] 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
[error] 	at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:219)
[error] 	at org.apache.spark.sql.execution.SparkPlan.executeColumnar(SparkPlan.scala:207)
[error] 	at org.apache.spark.sql.execution.InputAdapter.doExecuteColumnar(WholeStageCodegenExec.scala:520)
[error] 	at org.apache.spark.sql.execution.SparkPlan.$anonfun$executeColumnar$1(SparkPlan.scala:211)
[error] 	at org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:222)
[error] 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
[error] 	at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:219)
[error] 	at org.apache.spark.sql.execution.SparkPlan.executeColumnar(SparkPlan.scala:207)
[error] 	at org.apache.spark.sql.execution.ColumnarToRowExec.inputRDDs(Columnar.scala:204)
[error] 	at org.apache.spark.sql.execution.FilterExec.inputRDDs(basicPhysicalOperators.scala:237)
[error] 	at org.apache.spark.sql.execution.WholeStageCodegenExec.doExecute(WholeStageCodegenExec.scala:750)
[error] 	at org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:184)
[error] 	at org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:222)
[error] 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
[error] 	at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:219)
[error] 	at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:180)
[error] 	at org.apache.spark.sql.execution.UnionExec.$anonfun$doExecute$5(basicPhysicalOperators.scala:698)
[error] 	at scala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:286)
[error] 	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
[error] 	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
[error] 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
[error] 	at scala.collection.TraversableLike.map(TraversableLike.scala:286)
[error] 	at scala.collection.TraversableLike.map$(TraversableLike.scala:279)
[error] 	at scala.collection.AbstractTraversable.map(Traversable.scala:108)
[error] 	at org.apache.spark.sql.execution.UnionExec.doExecute(basicPhysicalOperators.scala:698)
[error] 	at org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:184)
[error] 	at org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:222)
[error] 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
[error] 	at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:219)
[error] 	at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:180)
[error] 	at org.apache.spark.sql.execution.exchange.ShuffleExchangeExec.inputRDD$lzycompute(ShuffleExchangeExec.scala:135)
[error] 	at org.apache.spark.sql.execution.exchange.ShuffleExchangeExec.inputRDD(ShuffleExchangeExec.scala:135)
[error] 	at org.apache.spark.sql.execution.exchange.ShuffleExchangeExec.mapOutputStatisticsFuture$lzycompute(ShuffleExchangeExec.scala:140)
[error] 	at org.apache.spark.sql.execution.exchange.ShuffleExchangeExec.mapOutputStatisticsFuture(ShuffleExchangeExec.scala:139)
[error] 	at org.apache.spark.sql.execution.exchange.ShuffleExchangeLike.$anonfun$submitShuffleJob$1(ShuffleExchangeExec.scala:68)
[error] 	at org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:222)
[error] 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
[error] 	at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:219)
[error] 	at org.apache.spark.sql.execution.exchange.ShuffleExchangeLike.submitShuffleJob(ShuffleExchangeExec.scala:68)
[error] 	at org.apache.spark.sql.execution.exchange.ShuffleExchangeLike.submitShuffleJob$(ShuffleExchangeExec.scala:67)
[error] 	at org.apache.spark.sql.execution.exchange.ShuffleExchangeExec.submitShuffleJob(ShuffleExchangeExec.scala:115)
[error] 	at org.apache.spark.sql.execution.adaptive.ShuffleQueryStageExec.shuffleFuture$lzycompute(QueryStageExec.scala:170)
[error] 	at org.apache.spark.sql.execution.adaptive.ShuffleQueryStageExec.shuffleFuture(QueryStageExec.scala:170)
[error] 	at org.apache.spark.sql.execution.adaptive.ShuffleQueryStageExec.doMaterialize(QueryStageExec.scala:172)
[error] 	at org.apache.spark.sql.execution.adaptive.QueryStageExec.materialize(QueryStageExec.scala:82)
[error] 	at org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.$anonfun$getFinalPhysicalPlan$5(AdaptiveSparkPlanExec.scala:256)
[error] 	at org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.$anonfun$getFinalPhysicalPlan$5$adapted(AdaptiveSparkPlanExec.scala:254)
[error] 	at scala.collection.Iterator.foreach(Iterator.scala:943)
[error] 	at scala.collection.Iterator.foreach$(Iterator.scala:943)
[error] 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
[error] 	at scala.collection.IterableLike.foreach(IterableLike.scala:74)
[error] 	at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
[error] 	at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
[error] 	at org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.$anonfun$getFinalPhysicalPlan$1(AdaptiveSparkPlanExec.scala:254)
[error] 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)
[error] 	at org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.getFinalPhysicalPlan(AdaptiveSparkPlanExec.scala:226)
[error] 	at org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.withFinalPlanUpdate(AdaptiveSparkPlanExec.scala:365)
[error] 	at org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.executeCollect(AdaptiveSparkPlanExec.scala:338)
[error] 	at org.apache.spark.sql.Dataset.collectFromPlan(Dataset.scala:3715)
[error] 	at org.apache.spark.sql.Dataset.$anonfun$collect$1(Dataset.scala:2971)
[error] 	at org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3706)
[error] 	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)
[error] 	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)
[error] 	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)
[error] 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)
[error] 	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)
[error] 	at org.apache.spark.sql.Dataset.withAction(Dataset.scala:3704)
[error] 	at org.apache.spark.sql.Dataset.collect(Dataset.scala:2971)
[error] 	at dk.aau.modelardb.Evaluate$.verifyError(Evaluate.scala:127)
[error] 	at dk.aau.modelardb.Evaluate$.verifier(Evaluate.scala:38)
[error] 	at dk.aau.modelardb.Main$.main(Main.scala:62)
[error] 	at dk.aau.modelardb.Main.main(Main.scala)
[error] 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[error] 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
[error] 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
[error] 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
[error] 	at sbt.Run.invokeMain(Run.scala:143)
[error] 	at sbt.Run.execute$1(Run.scala:93)
[error] 	at sbt.Run.$anonfun$runWithLoader$5(Run.scala:120)
[error] 	at sbt.Run$.executeSuccess(Run.scala:186)
[error] 	at sbt.Run.runWithLoader(Run.scala:120)
[error] 	at sbt.Run.run(Run.scala:127)
[error] 	at sbt.Defaults$.$anonfun$runTask$3(Defaults.scala:2028)
[error] 	at sbt.Defaults$.$anonfun$runTask$3$adapted(Defaults.scala:2026)
[error] 	at scala.Function1.$anonfun$compose$1(Function1.scala:49)
[error] 	at sbt.internal.util.$tilde$greater.$anonfun$$u2219$1(TypeFunctions.scala:62)
[error] 	at sbt.std.Transform$$anon$4.work(Transform.scala:68)
[error] 	at sbt.Execute.$anonfun$submit$2(Execute.scala:282)
[error] 	at sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:23)
[error] 	at sbt.Execute.work(Execute.scala:291)
[error] 	at sbt.Execute.$anonfun$submit$1(Execute.scala:282)
[error] 	at sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:265)
[error] 	at sbt.CompletionService$$anon$2.call(CompletionService.scala:64)
[error] 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[error] 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[error] 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[error] 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[error] 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[error] 	at java.base/java.lang.Thread.run(Thread.java:834)
